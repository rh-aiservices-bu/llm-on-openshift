[[source]]
url = "https://pypi.org/simple"
verify_ssl = true
name = "pypi"

[[source]]
url = "https://download.pytorch.org/whl/cu121/"
verify_ssl = false
name = "pytorch"

[packages]
cmake = "~=3.29.3"
einops= "~=0.8.0"
fastapi = "~=0.111.0"
filelock = "~=3.14.0"
lm-format-enforcer = "==0.9.8" # Fixed by vllm 0.4.2
ninja = "~=1.11.1.1"
numpy = "~=1.26.4"
nvidia-ml-py = "~=12.550.52"
openai = "~=1.28.1"
outlines = "==0.0.34" # Requires torch >= 2.1.0 - Fixed by vllm 0.4.2
pip = "~=24.0"
prometheus_client = "~=0.20.0"
prometheus-fastapi-instrumentator = "~=7.0.0"
psutil = "~=5.9.8"
py-cpuinfo = "~=9.0.0"
pydantic = "~=2.7.1"
pynvml = "==11.5.0"
ray = "~=2.21.0"
requests = "~=2.31.0"
sentencepiece = "~=0.2.0"
tiktoken = "==0.6.0" #  Required for DBRX tokenizer - Fixed by vllm 0.4.2
torch = {version = "==2.3.0+cu121", index = "pytorch"}
tokenizers = "~=0.19.1"
transformers = "~=4.40.2"
triton = "==2.3.0"
typing_extensions = "~=4.11.0"
uvicorn = {extras = ["standard"], version = "~=0.29.0"}
vllm = "==v0.4.2"
vllm-flash-attn = "==2.5.8.post1"
vllm-nccl-cu12 = "==2.18.1.0.4.0"
wheel = "~=0.43.0"
xformers = "==0.0.26.post1" # Requires torch 2.3.0 - Fixed by vllm 0.4.2

[dev-packages]

[requires]
python_version = "3.11"